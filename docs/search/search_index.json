{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AfriSenti-SemEval Shared Task 12 AfriSenti-SemEval: Sentiment Analysis for Low-resource African Languages using Twitter Dataset Motivation Due to the widespread use of the Internet and social media platforms, most languages are becoming digitally available. This allows for various artificial intelligence (AI) applications that enable tasks such as sentiment analysis, machine translation, hateful content detection, among others. According to UNESCO (2003), 30% of all living languages, around 2,058, are African languages. However, most of these languages do not have curated datasets for developing such AI applications. Recently, various individual and funded initiatives, such as the Lacuna Fund, have set out to reverse this trend and create such datasets for African languages. However, research is required to determine both the suitability of current natural language processing (NLP) techniques and the development of novel techniques to maximize the applications of such datasets. We believe that SemEval is the right venue, due to its popularity and widespread acceptance, to carry out shared tasks in these African languages to strengthen their further development. In this shared task, we have covered 12 African languages, namely 4 languages from Nigeria ( Hausa , Yoruba , Igbo , Nigerian Pigdin ), 2 from Ethiopia ( Amharic and Tigrinya ), Swahili from Kenya and Tanzania, Algerian Arabic dialect from Algeria, Tunisian Arabizi from Tunisia, Twi from Ghana, and 2 languages from South Africa ( isiZulu , Setswana ). Task Overview Previous shared tasks on different aspects of sentiment analysis includes Nakov et al., (2016), Pontiki et al., (2014), Ghosh et al., (2015) and so on. However, none of these tasks have covered African languages. The AfriSenti-SemEval shared task is based on a collection of Twitter datasets in 12 African languages for sentiment classification. The AfriSenti-SemEval Shared Task 12 consists of three sub-tasks. Participants can select one or more tasks depending on their preference. Task A: Monolingual Sentiment Classification: Given training data in a target language, determine whether an instance of tweet in that language is positive, negative, or neutral Task B: Sentiment Multilingual Sentiment Classification Given a combined training data from 10 African languages, determine whether a tweet instance in any of the given languages is positive, negative, or neutral. Task C: Zero-Shot Sentiment Classification Given unlabeled tweets in two African languages (Tigrinya and isiZulu), leverage any or all of the available training datasets in Subtasks 1 and 2 to determine whether an instance of a tweet in the two target languages is positive, negative, or neutral. Dataset Examples The dataset involves tweets labeled with three sentiment classes (positive, negative, neutral) in 12 African languages. Each tweet is annotated by three annotators. We use a form of majority vote to determine the sentiment of the tweet. See more in our paper ( Muhammad et al., 2022 , Yimam et al., 2020 ). Below is a sample dataset for the 4 Nigerian languges (Muhammad et al., 2022): The datasets are available on Github Important Dates Descriptions Deadlines Sample Data Ready 15 July 2022 Training Data Ready 1 September 2022 Evaluation Start 10 January 2023 Training Data Ready 1 September 2022 System Description Paper Due February 2023 Notification to authors March 2023 Camera ready due April 2023 SemEval workshop Summer 2023 (co-located with a major NLP conference) Communication Task Mailing List Task Slack Channel Task Organizers email References UNESCO. 2003. Sharing the world of difference. UNESCO. Preslav Nakov, Sara Rosenthal, Svetlana Kiritchenko, Saif M Mohammad, Zornitsa Kozareva, Alan Ritter, Veselin Stoyanov, and Xiaodan Zhu. 2016. Developing a successful SemEval task in sentiment analysis of twitter and other social media texts. Language Resources and Evaluation, 50(1):35\u201365. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar. 2014: SemEval-2014 Task 4: Aspect Based Sentiment Analysis, Dublin, Ireland Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso, Ekaterina Shutova, John Barnden, Antonio Reyes. 2015: SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter, Denver, Colorado Shamsuddeen Hassan Muhammad, David Ifeoluwa Adelani, Sebastian Ruder, Ibrahim Said Ahmad, Idris Abdulmumin, Bello Shehu Bello, Monojit Choudhury, Chris Chinenye Emezue, Saheed Salahudeen Abdullahi, Anuoluwapo Aremu, Alipio Jeorge, Pavel Brazdil. 2022, NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis, Marseille, France Seid Muhie Yimam, Hizkiel Mitiku Alemayehu, Abinew Ayele, Chris Biemann. 2020: Exploring Amharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models, Barcelona, Spain (Online) body { text-align: justify}","title":"Home"},{"location":"#afrisenti-semeval-shared-task-12","text":"AfriSenti-SemEval: Sentiment Analysis for Low-resource African Languages using Twitter Dataset","title":"AfriSenti-SemEval Shared Task 12"},{"location":"#motivation","text":"Due to the widespread use of the Internet and social media platforms, most languages are becoming digitally available. This allows for various artificial intelligence (AI) applications that enable tasks such as sentiment analysis, machine translation, hateful content detection, among others. According to UNESCO (2003), 30% of all living languages, around 2,058, are African languages. However, most of these languages do not have curated datasets for developing such AI applications. Recently, various individual and funded initiatives, such as the Lacuna Fund, have set out to reverse this trend and create such datasets for African languages. However, research is required to determine both the suitability of current natural language processing (NLP) techniques and the development of novel techniques to maximize the applications of such datasets. We believe that SemEval is the right venue, due to its popularity and widespread acceptance, to carry out shared tasks in these African languages to strengthen their further development. In this shared task, we have covered 12 African languages, namely 4 languages from Nigeria ( Hausa , Yoruba , Igbo , Nigerian Pigdin ), 2 from Ethiopia ( Amharic and Tigrinya ), Swahili from Kenya and Tanzania, Algerian Arabic dialect from Algeria, Tunisian Arabizi from Tunisia, Twi from Ghana, and 2 languages from South Africa ( isiZulu , Setswana ).","title":"Motivation"},{"location":"#task-overview","text":"Previous shared tasks on different aspects of sentiment analysis includes Nakov et al., (2016), Pontiki et al., (2014), Ghosh et al., (2015) and so on. However, none of these tasks have covered African languages. The AfriSenti-SemEval shared task is based on a collection of Twitter datasets in 12 African languages for sentiment classification. The AfriSenti-SemEval Shared Task 12 consists of three sub-tasks. Participants can select one or more tasks depending on their preference. Task A: Monolingual Sentiment Classification: Given training data in a target language, determine whether an instance of tweet in that language is positive, negative, or neutral Task B: Sentiment Multilingual Sentiment Classification Given a combined training data from 10 African languages, determine whether a tweet instance in any of the given languages is positive, negative, or neutral. Task C: Zero-Shot Sentiment Classification Given unlabeled tweets in two African languages (Tigrinya and isiZulu), leverage any or all of the available training datasets in Subtasks 1 and 2 to determine whether an instance of a tweet in the two target languages is positive, negative, or neutral.","title":"Task Overview"},{"location":"#dataset-examples","text":"The dataset involves tweets labeled with three sentiment classes (positive, negative, neutral) in 12 African languages. Each tweet is annotated by three annotators. We use a form of majority vote to determine the sentiment of the tweet. See more in our paper ( Muhammad et al., 2022 , Yimam et al., 2020 ). Below is a sample dataset for the 4 Nigerian languges (Muhammad et al., 2022): The datasets are available on Github","title":"Dataset Examples"},{"location":"#important-dates","text":"Descriptions Deadlines Sample Data Ready 15 July 2022 Training Data Ready 1 September 2022 Evaluation Start 10 January 2023 Training Data Ready 1 September 2022 System Description Paper Due February 2023 Notification to authors March 2023 Camera ready due April 2023 SemEval workshop Summer 2023 (co-located with a major NLP conference)","title":"Important Dates"},{"location":"#communication","text":"Task Mailing List Task Slack Channel Task Organizers email","title":"Communication"},{"location":"#references","text":"UNESCO. 2003. Sharing the world of difference. UNESCO. Preslav Nakov, Sara Rosenthal, Svetlana Kiritchenko, Saif M Mohammad, Zornitsa Kozareva, Alan Ritter, Veselin Stoyanov, and Xiaodan Zhu. 2016. Developing a successful SemEval task in sentiment analysis of twitter and other social media texts. Language Resources and Evaluation, 50(1):35\u201365. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar. 2014: SemEval-2014 Task 4: Aspect Based Sentiment Analysis, Dublin, Ireland Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso, Ekaterina Shutova, John Barnden, Antonio Reyes. 2015: SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter, Denver, Colorado Shamsuddeen Hassan Muhammad, David Ifeoluwa Adelani, Sebastian Ruder, Ibrahim Said Ahmad, Idris Abdulmumin, Bello Shehu Bello, Monojit Choudhury, Chris Chinenye Emezue, Saheed Salahudeen Abdullahi, Anuoluwapo Aremu, Alipio Jeorge, Pavel Brazdil. 2022, NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis, Marseille, France Seid Muhie Yimam, Hizkiel Mitiku Alemayehu, Abinew Ayele, Chris Biemann. 2020: Exploring Amharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models, Barcelona, Spain (Online) body { text-align: justify}","title":"References"},{"location":"about/","text":"","title":"About"},{"location":"baselines/","text":"","title":"Baselines"},{"location":"datasets/","text":"Competition Dataset The dataset for the competition is available at the following Github link: AfriSenti-SemEval Dataset The dataset consists of tweets labeled with three sentiment classes (positive, negative, neutral) in 12 African languages. Each tweet is annotated by three annotators. We use a form of majority vote to determine the sentiment of the tweet. See more in our paper: Below is a sample dataset in all the languages: Dataset Statistics Below is a statistic of the dataset in all the 12 languages. Languages Train Validation Test sXYZ sBlu z Jaobe X Blue 5.2 sXYZ Jaobe X Trail Data The trial data is available here. Training Data The training data is available here. Hyrdating Tweets table { border-collapse: collapse; } table, th, td { border: 1px solid black; } blockquote { border-left: solid blue; padding-left: 10px; }","title":"Datasets"},{"location":"datasets/#competition-dataset","text":"The dataset for the competition is available at the following Github link: AfriSenti-SemEval Dataset The dataset consists of tweets labeled with three sentiment classes (positive, negative, neutral) in 12 African languages. Each tweet is annotated by three annotators. We use a form of majority vote to determine the sentiment of the tweet. See more in our paper: Below is a sample dataset in all the languages:","title":"Competition Dataset"},{"location":"datasets/#dataset-statistics","text":"Below is a statistic of the dataset in all the 12 languages. Languages Train Validation Test sXYZ sBlu z Jaobe X Blue 5.2 sXYZ Jaobe X","title":"Dataset Statistics"},{"location":"datasets/#trail-data","text":"The trial data is available here.","title":"Trail Data"},{"location":"datasets/#training-data","text":"The training data is available here.","title":"Training Data"},{"location":"datasets/#hyrdating-tweets","text":"table { border-collapse: collapse; } table, th, td { border: 1px solid black; } blockquote { border-left: solid blue; padding-left: 10px; }","title":"Hyrdating Tweets"},{"location":"faqs/","text":"","title":"Faqs"},{"location":"organizer/","text":"Task Organizers Below is a list of organizers for AfriSenti-Shared Task 2022 Organizers Affliation shamsuddeen Hassan Muhammad Bayero University, Kano, Masakhane Idris Abdulmumin Ahmadu Bello UniversityZaria, Masakhane Seid Muhie Yimam Universit\u00e4t Hamburg Universit\u00e4t Hamburg, Hamburg; Masakhane Ibrahim Sa\u2019id Ahmad Bayero University, Kano Abinew Ali Ayele Bahir Dar University, Bahir Dar David Ifeoluwa Adelani MasaKhane; Saarland University Vukosi MasaKhane; Saarland University Sebastian Ruder Google Research Nedjma Ousidhoum The University of Cambridge Meriem Beloucif U Universit\u00e4t Hamburg","title":"Organizers"},{"location":"organizer/#task-organizers","text":"Below is a list of organizers for AfriSenti-Shared Task 2022 Organizers Affliation shamsuddeen Hassan Muhammad Bayero University, Kano, Masakhane Idris Abdulmumin Ahmadu Bello UniversityZaria, Masakhane Seid Muhie Yimam Universit\u00e4t Hamburg Universit\u00e4t Hamburg, Hamburg; Masakhane Ibrahim Sa\u2019id Ahmad Bayero University, Kano Abinew Ali Ayele Bahir Dar University, Bahir Dar David Ifeoluwa Adelani MasaKhane; Saarland University Vukosi MasaKhane; Saarland University Sebastian Ruder Google Research Nedjma Ousidhoum The University of Cambridge Meriem Beloucif U Universit\u00e4t Hamburg","title":"Task Organizers"},{"location":"paper/","text":"","title":"Paper Instructions"},{"location":"participation/","text":"How to Participate The organisers have defined the tasks and released the training data on date. The task is divided into 3 subtasks as indicated in the homepage (link). The participants can work on any or all the subtasks. Participants can form a team with multiple people or a single person team is okay. The participants can access the training data on our GitHub page (link). The participants can experiment with the training data to develop models. Usage of any external data or resource is allowed and highly encouraged. This process can run till the evaluation period. Evaluation period: On date, the organisers will release the test set containing instances without the labels. The participants will use their developed models to predict the labels for the instances and they have to create a submission file that follows exactly the same format of the training data. These prediction files should be submitted to Codalab submission portal (will be announced later). These predictions will be compared against the ground truth labels of the test data and the teams will be ranked on a leaderboard according to the performance score. Each team is encouraged to write a system description paper describing their submission system, analysis of their results, interesting insights and submit before date. Paper submission procedure will be announced later. After a review period, each team has to update their submitted paper based on the review feedback and submit the camera ready version. Accepted papers will be published as part of the proceedings of SemEval 2023 Workshop (link). To connect with the organisers or other participants about any questions or discussions, participants can join the Slack (link). Training Data Format AfriSentiEval 2022 featured datasets in thirteen African languages namely: Hausa, Yoruba, Igbo, Nigerian-Pidgin, Swahili, Amharic, Tunisian Arabizi, Kinyarwanda, Algerian Arabic dialect, Tigrinya, Twi, isiZulu, Setswana. The dataset can be download from the following link: [AfriSentiEval 2022 Dataset]( Results The Evaluation phase of Afri-Senti-SemEval 2023 will start on January 10, 2023 and end on 31 January 2023. The Evaluation results and rankings will be notified in the spreadsheet attachments to this page. We will list the usernames as they appear on CodaLab and the F1 score of your LAST submission. For more information, see Afri-Senti-SemEval 2023 result. 2.3 Evaluation We will use the AvgRec, Accuracy, and macro-average F1 measures for model evaluation. AvgRec, which provides results in a range of [0,1] favoured over standard accuracy because it is more robust to class imbalance (usually more natural classes than positive or negative as it can be seen in our Amharic dataset class distribution). Although accuracy reports the overall performance of the system, the F1 metric is calculated over the POSITIVE and the NEGATIVE classes exclusively.","title":"competitions"},{"location":"participation/#how-to-participate","text":"The organisers have defined the tasks and released the training data on date. The task is divided into 3 subtasks as indicated in the homepage (link). The participants can work on any or all the subtasks. Participants can form a team with multiple people or a single person team is okay. The participants can access the training data on our GitHub page (link). The participants can experiment with the training data to develop models. Usage of any external data or resource is allowed and highly encouraged. This process can run till the evaluation period. Evaluation period: On date, the organisers will release the test set containing instances without the labels. The participants will use their developed models to predict the labels for the instances and they have to create a submission file that follows exactly the same format of the training data. These prediction files should be submitted to Codalab submission portal (will be announced later). These predictions will be compared against the ground truth labels of the test data and the teams will be ranked on a leaderboard according to the performance score. Each team is encouraged to write a system description paper describing their submission system, analysis of their results, interesting insights and submit before date. Paper submission procedure will be announced later. After a review period, each team has to update their submitted paper based on the review feedback and submit the camera ready version. Accepted papers will be published as part of the proceedings of SemEval 2023 Workshop (link). To connect with the organisers or other participants about any questions or discussions, participants can join the Slack (link).","title":"How to Participate"},{"location":"participation/#training-data-format","text":"AfriSentiEval 2022 featured datasets in thirteen African languages namely: Hausa, Yoruba, Igbo, Nigerian-Pidgin, Swahili, Amharic, Tunisian Arabizi, Kinyarwanda, Algerian Arabic dialect, Tigrinya, Twi, isiZulu, Setswana. The dataset can be download from the following link: [AfriSentiEval 2022 Dataset](","title":"Training Data Format"},{"location":"participation/#results","text":"The Evaluation phase of Afri-Senti-SemEval 2023 will start on January 10, 2023 and end on 31 January 2023. The Evaluation results and rankings will be notified in the spreadsheet attachments to this page. We will list the usernames as they appear on CodaLab and the F1 score of your LAST submission. For more information, see Afri-Senti-SemEval 2023 result.","title":"Results"},{"location":"participation/#23-evaluation","text":"We will use the AvgRec, Accuracy, and macro-average F1 measures for model evaluation. AvgRec, which provides results in a range of [0,1] favoured over standard accuracy because it is more robust to class imbalance (usually more natural classes than positive or negative as it can be seen in our Amharic dataset class distribution). Although accuracy reports the overall performance of the system, the F1 metric is calculated over the POSITIVE and the NEGATIVE classes exclusively.","title":"2.3 Evaluation"}]}